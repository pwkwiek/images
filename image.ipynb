{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# image operations in pyton"
      ],
      "metadata": {
        "id": "i69NgwpAsB3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### various ways to import and display an image"
      ],
      "metadata": {
        "id": "ELQRSsiobKPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An RGB image refers to an image where each pixel is defined by the amount of red, green, and blue colors. It is created by using three different colormaps for these colors and visualized as a 2-D matrix.\n",
        "\n",
        "Grayscale image is one of the digital image categories where every pixel may only be of varying shades of gray without any color information.\n",
        "\n",
        "In a grayscale image, every pixel digitized can hold an intensity value of brightness for the gray shade in consideration.\n",
        "\n",
        "In most cases, these range from 0 â€“ 255 in an 8-bit grayscale image whereby 0 is represented by black, 255 by white and all other values lies between the two extremes as grey."
      ],
      "metadata": {
        "id": "GhiNpBrcoXlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matplotlib**\n",
        "\n",
        "Best for: Quick image display and plotting\n",
        "\n",
        "Supports: JPEG, PNG (does not support BMP, TIFF)"
      ],
      "metadata": {
        "id": "E6hEvWypbr54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = plt.imread(\"image.jpg\")\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XSaqsgDrbsOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**openCV**\n",
        "\n",
        "Best for: Image processing, computer vision applications\n",
        "\n",
        "Supports: JPEG, PNG, BMP, TIFF, etc."
      ],
      "metadata": {
        "id": "muAFvjNTbUDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "image = cv2.imread(\"image.jpg\")  # Load image in BGR format"
      ],
      "metadata": {
        "id": "0QFPzwvIbO3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display image in new window\n",
        "#cv2.imshow(\"Image\", image)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "_Ad32CK8eQqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for proper display\n",
        "\n",
        "# Display using Matplotlib\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y1uGxbZPdtZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PIL (Pillow)**\n",
        "\n",
        "Best for: General image handling, resizing, filtering\n",
        "\n",
        "Supports: JPEG, PNG, BMP, GIF, etc."
      ],
      "metadata": {
        "id": "edMhfY9LbXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"image.jpg\")  # Load image\n",
        "#image.show()  # Display image in new window\n",
        "\n",
        "#image_array = np.array(image)  # Convert to NumPy array"
      ],
      "metadata": {
        "id": "Ol-OMGaXbhnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FKcTvf3neft0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imageio**\n",
        "\n",
        "Best for: Handling various formats, including GIFs and medical imaging (DICOM)\n",
        "\n",
        "Supports: JPEG, PNG, GIF, BMP, TIFF, DICOM, etc."
      ],
      "metadata": {
        "id": "BSOi2idKbuuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio.v3 as iio\n",
        "\n",
        "image = iio.imread(\"image.jpg\")"
      ],
      "metadata": {
        "id": "UWGQvCqcbu4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bv6SksDoeu47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scikit-Image**\n",
        "\n",
        "Best for: Image manipulation, scientific computing\n",
        "\n",
        "Supports: JPEG, PNG, BMP, TIFF, etc."
      ],
      "metadata": {
        "id": "Lrf7-8dZcA8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "\n",
        "image = io.imread(\"image.jpg\")\n",
        "io.imshow(image)"
      ],
      "metadata": {
        "id": "TrGW_FEicBEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow**\n",
        "\n",
        "Best for: Deep learning, TensorFlow/Keras models\n",
        "\n",
        "Supports: JPEG, PNG"
      ],
      "metadata": {
        "id": "PXTNPTWDcHck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "image = tf.keras.utils.load_img(\"image.jpg\")\n",
        "#image = tf.keras.utils.img_to_array(image)  # Convert to NumPy array"
      ],
      "metadata": {
        "id": "KxVtw_0kcQv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tIVMDANyfAtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PyTorch**\n",
        "\n",
        "Best for: Deep learning (PyTorch)\n",
        "\n",
        "Supports: JPEG, PNG"
      ],
      "metadata": {
        "id": "jz6DQRDJcRmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "\n",
        "image = read_image(\"image.jpg\")  # Loads image as a tensor"
      ],
      "metadata": {
        "id": "jN9pQzBbcWwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy**\n",
        "\n",
        "numpy.loadtxt for raw image data\n",
        "\n",
        "Best for: Custom datasets in CSV or TXT format\n",
        "\n",
        "Useful when image data is stored in plain text files"
      ],
      "metadata": {
        "id": "agx0RdY4caK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "image = np.loadtxt(\"image.txt\")  # Load pixel values from a text file\n",
        "\n",
        "plt.imshow(image, cmap='gray') # Use matplotlib to display image\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rljiFg1Tcw-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### image representation"
      ],
      "metadata": {
        "id": "xCJdREtahJEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color space models are systems used to represent colors in a standardized way\n",
        "these models help in processing, analyzing, and manipulating colors in images or videos\n",
        "\n",
        "Different color space models are used for various applications like image processing, computer vision, and graphics design"
      ],
      "metadata": {
        "id": "dhTusCY2onJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image in color (BGR format)\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n",
        "\n",
        "# Split the image into its channels\n",
        "R, G, B = cv2.split(image)\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Display images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(R, cmap=\"Reds\")\n",
        "axes[1].set_title(\"Red Channel\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(G, cmap=\"Greens\")\n",
        "axes[2].set_title(\"Green Channel\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "axes[3].imshow(B, cmap=\"Blues\")\n",
        "axes[3].set_title(\"Blue Channel\")\n",
        "axes[3].axis(\"off\")\n",
        "\n",
        "axes[4].imshow(gray, cmap=\"gray\")\n",
        "axes[4].set_title(\"Grayscale Image\")\n",
        "axes[4].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5GvkorXghLGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image in color (BGR format)\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for correct display\n",
        "\n",
        "# Convert RGB to YUV\n",
        "yuv_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "# Split the YUV channels\n",
        "Y, U, V = cv2.split(yuv_image)\n",
        "\n",
        "# Display images\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "axes[0].imshow(yuv_image)\n",
        "axes[0].set_title(\"YUV Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(Y, cmap=\"gray\")\n",
        "axes[1].set_title(\"Y Channel (Luminance)\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(U, cmap=\"coolwarm\")\n",
        "axes[2].set_title(\"U Channel (Chrominance Blue)\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "axes[3].imshow(V, cmap=\"coolwarm\")\n",
        "axes[3].set_title(\"V Channel (Chrominance Red)\")\n",
        "axes[3].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZDqHTx6Bh36H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image in color (BGR format)\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for correct display\n",
        "\n",
        "# Convert RGB to HSV\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "# Split the HSV channels\n",
        "H, S, V = cv2.split(hsv_image)\n",
        "\n",
        "# Display images\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "axes[0].imshow(hsv_image)\n",
        "axes[0].set_title(\"HSV Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(H, cmap=\"hsv\")\n",
        "axes[1].set_title(\"H Channel (Hue)\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(S, cmap=\"gray\")\n",
        "axes[2].set_title(\"S Channel (Saturation)\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "axes[3].imshow(V, cmap=\"gray\")\n",
        "axes[3].set_title(\"V Channel (Value)\")\n",
        "axes[3].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8JgtDgpbiFDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different methods of image segmentation"
      ],
      "metadata": {
        "id": "dO1PVSsoiSkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* image segmentation is a process in computer vision where an image is divided into multiple segments or regions to make it more meaningful and easier to analyze\n",
        "* the goal is to assign a label to every pixel in an image such that pixels with the same label share certain characteristics (e.g., color, texture, intensity, or object boundaries)\n",
        "* it's widely used in tasks like object detection, medical imaging, and autonomous vehicles"
      ],
      "metadata": {
        "id": "dExTI7z3ruGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Necessary Libraries\n",
        "from skimage import filters\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Sample Image Import\n",
        "image =  mpimg.imread('image.jpg')\n",
        "gray_image = rgb2gray(image)\n",
        "\n",
        "# Setting the plot size to 15,15\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for i in range(6):\n",
        "\n",
        "  # Iterating different thresholds\n",
        "  binarized_gray = (gray_image > i*0.1)*1\n",
        "  plt.subplot(5,2,i+1)\n",
        "\n",
        "  # Rounding of the threshold\n",
        "  # value to 1 decimal point\n",
        "  plt.title(\"Threshold: >\"+str(round(i*0.1,1)))\n",
        "\n",
        "  # Displaying the binarized image\n",
        "  # of various thresholds\n",
        "  plt.imshow(binarized_gray, cmap = 'gray')\n",
        "\n",
        "plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "7TgPZOUeiUJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.data import page\n",
        "from skimage.filters import threshold_otsu, threshold_niblack, threshold_sauvola\n",
        "\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 9\n",
        "\n",
        "img = cv2.imread('image.jpg')\n",
        "image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "binary_global = image > threshold_otsu(image)\n",
        "\n",
        "window_size = 25\n",
        "thresh_niblack = threshold_niblack(image, window_size=window_size, k=0.8)\n",
        "thresh_sauvola = threshold_sauvola(image, window_size=window_size)\n",
        "\n",
        "binary_niblack = image > thresh_niblack\n",
        "binary_sauvola = image > thresh_sauvola\n",
        "\n",
        "plt.figure(figsize=(8, 7))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(image, cmap=plt.cm.gray)\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title('Global Threshold')\n",
        "plt.imshow(binary_global, cmap=plt.cm.gray)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(binary_niblack, cmap=plt.cm.gray)\n",
        "plt.title('Niblack Threshold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(binary_sauvola, cmap=plt.cm.gray)\n",
        "plt.title('Sauvola Threshold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8AKYzAssw2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.util import random_noise\n",
        "from skimage import feature\n",
        "\n",
        "image = mpimg.imread('image.jpg')\n",
        "image = rgb2gray(image)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = feature.canny(image)\n",
        "edges2 = feature.canny(image, sigma=3)\n",
        "\n",
        "# display results\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 3))\n",
        "\n",
        "ax[0].imshow(image, cmap='gray')\n",
        "ax[0].set_title('image', fontsize=20)\n",
        "\n",
        "ax[1].imshow(edges1, cmap='gray')\n",
        "ax[1].set_title(r'Canny filter, $\\sigma=1$', fontsize=20)\n",
        "\n",
        "ax[2].imshow(edges2, cmap='gray')\n",
        "ax[2].set_title(r'Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "for a in ax:\n",
        "    a.axis('off')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eDbIptzJtJlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.filters import try_all_threshold\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread('image.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "fig, ax = try_all_threshold(img, figsize=(10, 8), verbose=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SzLDf4wRtZDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Read in the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Change color to RGB (from BGR)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Reshaping the image into a 2D array of pixels and 3 color values (RGB)\n",
        "pixel_vals = image.reshape((-1,3))\n",
        "\n",
        "# Convert to float type\n",
        "pixel_vals = np.float32(pixel_vals)\n",
        "\n",
        "#the below line of code defines the criteria for the algorithm to stop running,\n",
        "#which will happen is 100 iterations are run or the epsilon (which is the required accuracy)\n",
        "#becomes 85%\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85)\n",
        "\n",
        "# then perform k-means clustering with number of clusters defined as 3\n",
        "#also random centres are initially choosed for k-means clustering\n",
        "k = 3\n",
        "retval, labels, centers = cv2.kmeans(pixel_vals, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "# convert data into 8-bit values\n",
        "centers = np.uint8(centers)\n",
        "segmented_data = centers[labels.flatten()]\n",
        "\n",
        "# reshape data into the original image dimensions\n",
        "segmented_image = segmented_data.reshape((image.shape))\n",
        "\n",
        "plt.imshow(segmented_image)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "1Bu2SilhtUW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### various image augmentation methods"
      ],
      "metadata": {
        "id": "HTkhiyvSiUys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### color transformation"
      ],
      "metadata": {
        "id": "ZmWPoYUhoBr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenCV: cv2.convertScaleAbs()**\n",
        "\n",
        "alpha (Contrast): >1 increases contrast, <1 decreases contrast\n",
        "\n",
        "beta (Brightness): Positive values brighten, negative values darken"
      ],
      "metadata": {
        "id": "HlnjuzYqjp-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for correct display\n",
        "\n",
        "# Adjust Brightness and Contrast\n",
        "alpha = 1.5  # Contrast (1.0 = no change)\n",
        "beta = 50    # Brightness (0 = no change)\n",
        "bright_contrast_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(bright_contrast_image)\n",
        "axes[1].set_title(f\"Brightness & Contrast Adjusted\\nAlpha={alpha}, Beta={beta}\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sFEeww8CiYrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy**\n",
        "\n",
        "simply add brightness to all pixels and clip values above 255"
      ],
      "metadata": {
        "id": "LhsCzEhpkBG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase brightness by adding a constant\n",
        "bright_image = np.clip(image + 50, 0, 255).astype(np.uint8)  # Clip values to valid range\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(bright_image)\n",
        "axes[1].set_title(\"Brightness\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CX_3jJoPj8O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**adjust contrast using Histogram Equalization**"
      ],
      "metadata": {
        "id": "g5hqyd9AkNgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "equalized = cv2.equalizeHist(image_gray)  # Apply histogram equalization\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(image_gray, cmap=\"gray\")\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(equalized, cmap=\"gray\")\n",
        "axes[1].set_title(\"Equalized Image\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0pRZvV31kN92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**adjust hue using HSV color space**\n",
        "\n",
        "shifting hue allows changing colors while keeping brightness & saturation constant"
      ],
      "metadata": {
        "id": "-BhwlgaKkT7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to HSV\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "# Adjust Hue\n",
        "hue_shift = 20  # Change in Hue (0-180 for OpenCV)\n",
        "hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift) % 180  # Modify Hue and wrap around\n",
        "\n",
        "# Convert back to RGB\n",
        "hue_adjusted = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "# Display images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(hue_adjusted)\n",
        "axes[1].set_title(f\"Hue Adjusted (+{hue_shift})\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0VOiyohNkUEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### image blurring"
      ],
      "metadata": {
        "id": "shOtRzmHoIYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image blurring** involves reducing the clarity or sharpness of an image, making it appear less distinct. This is achieved using various low-pass filter kernels.\n",
        "\n",
        "Benefits of Blurring:\n",
        "* Noise Reduction: Since noise is generally a high-frequency component, applying a low-pass filter helps suppress unwanted noise.\n",
        "* Image Smoothing: Blurring enhances the smoothness of an image by reducing sharp variations in intensity.\n",
        "* Removal of Low-Intensity Edges: Subtle, less significant edges are diminished, improving overall image aesthetics.\n",
        "* Concealing Details When Needed: In certain situations, such as law enforcement cases, blurring is used to obscure sensitive details like the identity of victims."
      ],
      "metadata": {
        "id": "EWKvhpiWnqhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread('image.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for correct display\n",
        "\n",
        "# Display images\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title(\"Oryginal Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Gaussian Blur\n",
        "Gaussian = cv2.GaussianBlur(image, (7, 7), 0)\n",
        "axes[1].imshow(Gaussian)\n",
        "axes[1].set_title(\"Gaussian Blurring\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "# Bilateral Blur\n",
        "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
        "axes[2].imshow(bilateral)\n",
        "axes[2].set_title(\"Bilateral Blur\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "# Median Blur\n",
        "median = cv2.medianBlur(image, 5)\n",
        "axes[3].imshow(median)\n",
        "axes[3].set_title(\"Median Blur \")\n",
        "axes[3].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CyfIlmEumEFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### noise injection"
      ],
      "metadata": {
        "id": "oD-q6Pmxtvf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Read Image\n",
        "img = cv2.imread('image.jpg') # Color image\n",
        "\n",
        "# Convert the image to grayscale\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Genearte noise with same shape as that of the image\n",
        "noise = np.random.normal(0, 50, img_gray.shape)\n",
        "\n",
        "# Add the noise to the image\n",
        "img_noised = img_gray + noise\n",
        "\n",
        "# Clip the pixel values to be between 0 and 255.\n",
        "img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)\n",
        "\n",
        "plt.imshow(img_noised, cmap='gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "cftC8EZJtyYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### geometric transformation"
      ],
      "metadata": {
        "id": "-MURcgGKo5OO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geometric transformations allow modifying an image's position, orientation, or shape using mathematical operations. Among them are:\n",
        "\n",
        "* Translation:\tMoves the image\t- cv2.warpAffine()\n",
        "\n",
        "* Rotation:\tRotates image by an angle\t- cv2.getRotationMatrix2D(), cv2.warpAffine()\n",
        "\n",
        "* Scaling:\tEnlarges or shrinks image -\tcv2.resize()\n",
        "\n",
        "* Flipping:\tMirrors image horizontally/vertically\t- cv2.flip()\n",
        "\n",
        "* Affine Transform:\tShears or distorts image\t- cv2.getAffineTransform(), cv2.warpAffine()"
      ],
      "metadata": {
        "id": "xkqTCUasrA-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Define translation matrix (shift right by 50 pixels, down by 30 pixels)\n",
        "tx, ty = 50, 30\n",
        "translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "\n",
        "# Apply translation\n",
        "translated_image = cv2.warpAffine(image, translation_matrix, (image.shape[1], image.shape[0]))\n",
        "\n",
        "# Display images\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(translated_image)\n",
        "plt.title(\"Translated Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W6nszD7jo8AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle = 45  # Rotation angle\n",
        "center = (image.shape[1] // 2, image.shape[0] // 2)  # Center of rotation\n",
        "\n",
        "# Rotation matrix\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
        "\n",
        "# Apply rotation\n",
        "rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))\n",
        "\n",
        "plt.imshow(rotated_image)\n",
        "plt.title(\"Rotated Image (45Â°)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oxsAh_17qSFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale factors\n",
        "scale_x, scale_y = 1.5, 1.5  # 1.5x enlargement\n",
        "\n",
        "# Resize image\n",
        "scaled_image = cv2.resize(image, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "plt.imshow(scaled_image)\n",
        "plt.title(\"Scaled Image (1.5x)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y2GBzUddqV0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flipped_horizontally = cv2.flip(image, 1)  # Flip left-right\n",
        "flipped_vertically = cv2.flip(image, 0)  # Flip up-down\n",
        "flipped_both = cv2.flip(image, -1)  # Flip both axes\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(flipped_horizontally)\n",
        "plt.title(\"Flipped Horizontally\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(flipped_vertically)\n",
        "plt.title(\"Flipped Vertically\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(flipped_both)\n",
        "plt.title(\"Flipped Both Ways\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ReWX1xbqZXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols, ch = image.shape\n",
        "\n",
        "# Define three points before and after transformation\n",
        "pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
        "pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
        "\n",
        "# Compute transformation matrix\n",
        "affine_matrix = cv2.getAffineTransform(pts1, pts2)\n",
        "\n",
        "# Apply transformation\n",
        "affine_transformed = cv2.warpAffine(image, affine_matrix, (cols, rows))\n",
        "\n",
        "plt.imshow(affine_transformed)\n",
        "plt.title(\"Affine Transformed Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RhCVpCTyqcic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}